Teste TÃ©cnico - Intuitive Care
Candidato: Anderson AssumpÃ§Ã£o Junior Vaga: EstÃ¡gio em Desenvolvimento.

Este repositÃ³rio contÃ©m a soluÃ§Ã£o para o desafio tÃ©cnico, abrangendo ETL de dados pÃºblicos da ANS, validaÃ§Ã£o de dados, modelagem de banco de dados e anÃ¡lise SQL.

ğŸ›  Tecnologias Escolhidas
Linguagem: Python 3.14 (Escolhido pela robustez em manipulaÃ§Ã£o de dados com Pandas e agilidade de desenvolvimento).

Banco de Dados: SQLite (Escolhido pela portabilidade para este teste, dispensando instalaÃ§Ã£o de servidores externos, mas mantendo sintaxe SQL compatÃ­vel com MySQL/PostgreSQL).

Bibliotecas Principais: pandas, requests, lxml.

ğŸš€ Como Executar o Projeto
O projeto foi construÃ­do de forma modular. Siga a ordem abaixo para reproduzir todo o pipeline:

1. ConfiguraÃ§Ã£o Inicial
Certifique-se de ter o Python instalado e as dependÃªncias:

Bash
# CriaÃ§Ã£o do ambiente virtual (recomendado)
python -m venv venv
source venv/bin/activate  # Linux/Mac
# venv\Scripts\activate   # Windows

# InstalaÃ§Ã£o das dependÃªncias
pip install pandas requests lxml
2. Pipeline de ExecuÃ§Ã£o
Passo 1: ETL e ConsolidaÃ§Ã£o (Item 1) Baixa, extrai, trata encoding e consolida os CSVs trimestrais.

Bash
python src/processor.py
SaÃ­da: Gera data/consolidado.csv.

Passo 2: AnÃ¡lise e AgregaÃ§Ã£o (Item 2) Gera estatÃ­sticas por operadora/UF e valida matematicamente os CNPJs.

Bash
python src/aggregator.py
SaÃ­da: Gera data/despesas_agregadas.csv e exibe relatÃ³rio de validaÃ§Ã£o no terminal.

Passo 3: Banco de Dados e Carga (Item 3) Cria o banco SQLite, estrutura as tabelas (DDL) e importa os dados (DML).

Bash
python src/db_loader.py
SaÃ­da: Cria sql/teste_ans.db e popula as tabelas.

Passo 4: Queries AnalÃ­ticas (Item 3.4) Executa as queries SQL complexas exigidas no teste (Top 5 Crescimento, DistribuiÃ§Ã£o UF, ConsistÃªncia).

Bash
python src/analytics_queries.py
âš–ï¸ DiÃ¡rio de DecisÃµes (Trade-offs)
DocumentaÃ§Ã£o das escolhas tÃ©cnicas baseadas nos requisitos do teste.

1. EstratÃ©gia de Processamento de Arquivos (ETL)
DecisÃ£o: Processamento Incremental (chunksize).


Contexto: O teste questionou entre processar em memÃ³ria ou incrementalmente.

Justificativa: Optei por ler os CSVs em chunks (lotes) de 5.000 linhas. Embora o volume atual caiba na memÃ³ria, essa abordagem garante que a aplicaÃ§Ã£o seja escalÃ¡vel e nÃ£o trave caso a ANS disponibilize arquivos de Gigabytes no futuro.

2. Tratamento de Encoding (ResiliÃªncia)
Problema: Os arquivos da ANS misturam encodings (UTF-8 e Latin-1), gerando caracteres quebrados ("Mojibake") como FUNDAÃƒÃƒO.

SoluÃ§Ã£o: Implementei uma estratÃ©gia hÃ­brida de decodificaÃ§Ã£o. O script tenta ler como utf-8 primeiro (padrÃ£o moderno); se falhar, faz fallback para latin1 com tratamento de erro. Isso garantiu 100% de legibilidade nos nomes das operadoras.

3. ValidaÃ§Ã£o de Dados
DecisÃ£o: ValidaÃ§Ã£o MatemÃ¡tica de CNPJ.


Contexto: O teste pedia tratamento para CNPJs invÃ¡lidos.

Justificativa: Em vez de apenas verificar o tamanho da string (regex), implementei a classe DataValidator que calcula os DÃ­gitos Verificadores (mÃ³dulo 11). Isso garante que apenas empresas reais sejam processadas, aumentando a qualidade do dado final.

4. Modelagem do Banco de Dados (NormalizaÃ§Ã£o)

DecisÃ£o: OpÃ§Ã£o B - Tabelas Normalizadas.

Estrutura: Separei os dados em duas tabelas principais:

operadoras (DimensÃ£o): reg_ans (PK), cnpj, razao_social, uf.

despesas (Fatos): id, reg_ans (FK), valor, trimestre.

Justificativa:

Integridade: Evita que uma mesma operadora tenha nomes diferentes em trimestres diferentes.

Armazenamento: O nome da operadora (string longa) Ã© armazenado apenas uma vez, e nÃ£o repetido milhÃµes de vezes na tabela de despesas, economizando espaÃ§o e processamento.

5. Tipagem de Dados no SQL
DecisÃ£o: Uso de DECIMAL/REAL para valores monetÃ¡rios.

Justificativa: NÃ£o utilizei FLOAT simples devido a erros de precisÃ£o em ponto flutuante. Para sistemas financeiros/contÃ¡beis, a precisÃ£o decimal Ã© crÃ­tica.

ğŸ“‚ Estrutura do Projeto
Plaintext
â”œâ”€â”€ data/                   # Armazenamento de arquivos
â”‚   â”œâ”€â”€ raw/                # Arquivos brutos baixados (ZIPs)
â”‚   â”œâ”€â”€ consolidado.csv     # Resultado do ETL
â”‚   â””â”€â”€ despesas_agregadas.csv # Resultado da AgregaÃ§Ã£o
â”œâ”€â”€ sql/
â”‚   â””â”€â”€ teste_ans.db        # Banco de Dados SQLite
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ processor.py        # Script ETL (ExtraÃ§Ã£o e Limpeza)
â”‚   â”œâ”€â”€ validator.py        # Regras de validaÃ§Ã£o (CNPJ)
â”‚   â”œâ”€â”€ aggregator.py       # LÃ³gica de estatÃ­stica e agregaÃ§Ã£o
â”‚   â”œâ”€â”€ db_loader.py        # Script de criaÃ§Ã£o e carga do Banco
â”‚   â””â”€â”€ analytics_queries.py # RelatÃ³rios SQL automatizados
â””â”€â”€ README.md               # DocumentaÃ§Ã£o